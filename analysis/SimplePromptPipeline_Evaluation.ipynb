{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a65eeb9",
   "metadata": {},
   "source": [
    "# Evaluating SimplePromptPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9949195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GPT-3 ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [01:31<00:00,  1.58s/entry, Last: 0.67s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-3simple_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251208_095510.log\n",
      "\n",
      "=== Running GPT-4o-mini ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [01:55<00:00,  1.99s/entry, Last: 1.43s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-4o-minisimple_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251208_095641.log\n",
      "\n",
      "=== Running GPT-4o ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [01:27<00:00,  1.51s/entry, Last: 1.25s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-4osimple_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251208_095836.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root (the directory that contains \"src\")\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- Imports from your project ---\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptPipeline\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptDescPipeline\n",
    "from src.app.Evaluator import Evaluator\n",
    "from src.llms.LLM_Wrappers import AbstractLLM\n",
    "\n",
    "# --- Define Models to Evaluate ---\n",
    "models = {\n",
    "    \"GPT-3\": AbstractLLM.from_name(\"gpt-3.5-turbo\"),\n",
    "    \"GPT-4o-mini\": AbstractLLM.from_name(model_name=\"gpt-4o-mini\"),\n",
    "    \"GPT-4o\": AbstractLLM.from_name(model_name=\"gpt-4o\"),\n",
    "}\n",
    "\n",
    "# --- Files to Evaluate ---\n",
    "ground_truth_files = [\n",
    "    \"../src/data/Q17_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q19_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q20_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q21_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q22_Annotated_Responses.json\",\n",
    "]\n",
    "\n",
    "# --- Output and Results Directories ---\n",
    "output_dir = \"../outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_dir = os.path.join(\"../analysis\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Parameters ---\n",
    "min_conf = 0.7\n",
    "records = []\n",
    "\n",
    "evaluators = []\n",
    "\n",
    "# --- Run pipelines + evaluate ---\n",
    "for model_name, llm in models.items():\n",
    "    model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    print(f\"\\n=== Running {model_name} ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run pipeline\n",
    "        pipeline = SimplePromptPipeline(\n",
    "            llm=llm,\n",
    "            input_path=gt_path,\n",
    "            output_dir=output_dir,\n",
    "            output_name=model_suffix+\"simple\",\n",
    "        )\n",
    "        output_path = pipeline.run()\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        evaluators.append(evaluator)\n",
    "\n",
    "        records.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_better = pd.DataFrame(records)\n",
    "summary_df_better = (\n",
    "    df_better.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_better.to_csv(os.path.join(results_dir, \"per_question_results.csv\"), index=False)\n",
    "summary_df_better.to_csv(os.path.join(results_dir, \"summary_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b89770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ“Š Per-Question Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_02547\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02547_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_02547_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_02547_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_02547_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_02547_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02547_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_02547_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_02547_row0_col1\" class=\"data row0 col1\" >Q17</td>\n",
       "      <td id=\"T_02547_row0_col2\" class=\"data row0 col2\" >0.537</td>\n",
       "      <td id=\"T_02547_row0_col3\" class=\"data row0 col3\" >0.614</td>\n",
       "      <td id=\"T_02547_row0_col4\" class=\"data row0 col4\" >0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02547_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_02547_row1_col0\" class=\"data row1 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_02547_row1_col1\" class=\"data row1 col1\" >Q17</td>\n",
       "      <td id=\"T_02547_row1_col2\" class=\"data row1 col2\" >0.585</td>\n",
       "      <td id=\"T_02547_row1_col3\" class=\"data row1 col3\" >0.747</td>\n",
       "      <td id=\"T_02547_row1_col4\" class=\"data row1 col4\" >0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02547_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_02547_row2_col0\" class=\"data row2 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_02547_row2_col1\" class=\"data row2 col1\" >Q17</td>\n",
       "      <td id=\"T_02547_row2_col2\" class=\"data row2 col2\" >0.617</td>\n",
       "      <td id=\"T_02547_row2_col3\" class=\"data row2 col3\" >0.699</td>\n",
       "      <td id=\"T_02547_row2_col4\" class=\"data row2 col4\" >0.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x175964f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ§® Average Precision/Recall per Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6dfb2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6dfb2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6dfb2_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_6dfb2_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_6dfb2_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6dfb2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6dfb2_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_6dfb2_row0_col1\" class=\"data row0 col1\" >0.537</td>\n",
       "      <td id=\"T_6dfb2_row0_col2\" class=\"data row0 col2\" >0.614</td>\n",
       "      <td id=\"T_6dfb2_row0_col3\" class=\"data row0 col3\" >0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6dfb2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6dfb2_row1_col0\" class=\"data row1 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_6dfb2_row1_col1\" class=\"data row1 col1\" >0.617</td>\n",
       "      <td id=\"T_6dfb2_row1_col2\" class=\"data row1 col2\" >0.699</td>\n",
       "      <td id=\"T_6dfb2_row1_col3\" class=\"data row1 col3\" >0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6dfb2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6dfb2_row2_col0\" class=\"data row2 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_6dfb2_row2_col1\" class=\"data row2 col1\" >0.585</td>\n",
       "      <td id=\"T_6dfb2_row2_col2\" class=\"data row2 col2\" >0.747</td>\n",
       "      <td id=\"T_6dfb2_row2_col3\" class=\"data row2 col3\" >0.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x175d75590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display Results (with graceful fallback if jinja2 missing) ---\n",
    "print(\"\\n\\n=== ðŸ“Š Per-Question Results ===\")\n",
    "try:\n",
    "    display(df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "\n",
    "print(\"\\n\\n=== ðŸ§® Average Precision/Recall per Model ===\")\n",
    "try:\n",
    "    display(summary_df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(summary_df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20484069",
   "metadata": {},
   "source": [
    "## Investigate the evaluations further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405506a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Evaluation Metrics at min_confidence = 0.7 ===\n",
      "{\n",
      "  \"global\": {\n",
      "    \"precision\": 0.45652173913043476,\n",
      "    \"recall\": 0.7590361445783133,\n",
      "    \"f1-score\": 0.5701357466063348\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluation Metrics at min_confidence = 0.8 ===\n",
      "{\n",
      "  \"global\": {\n",
      "    \"precision\": 0.45454545454545453,\n",
      "    \"recall\": 0.7228915662650602,\n",
      "    \"f1-score\": 0.5581395348837209\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=== Evaluation Metrics at min_confidence = 0.9 ===\n",
      "{\n",
      "  \"global\": {\n",
      "    \"precision\": 0.44144144144144143,\n",
      "    \"recall\": 0.5903614457831325,\n",
      "    \"f1-score\": 0.5051546391752577\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval = evaluators[0]  # Example: inspect the first evaluator\n",
    "\n",
    "for min_conf in (0.7, 0.8, 0.9):\n",
    "    metrics = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "    print(\"\\n\\n=== Evaluation Metrics at min_confidence =\", min_conf, \"===\")\n",
    "    # I only want to see the global metrics here)\n",
    "    results = {\"global\": metrics[\"global\"]}\n",
    "\n",
    "    print(json.dumps(results, indent=2))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d03aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Œ Evaluator: Q17_Annotated_Responses_GPT-3_annotated.json\n",
      "================================================================================\n",
      " Min Confidence Precision Recall F1-Score\n",
      "            0.7     0.362  0.602    0.452\n",
      "            0.8     0.362  0.554    0.438\n",
      "            0.9     0.293  0.325    0.309\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Œ Evaluator: Q17_Annotated_Responses_GPT-4o-mini_annotated.json\n",
      "================================================================================\n",
      " Min Confidence Precision Recall F1-Score\n",
      "            0.7     0.417  0.759    0.538\n",
      "            0.8     0.415  0.675    0.514\n",
      "            0.9     0.360  0.386    0.372\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Œ Evaluator: Q17_Annotated_Responses_GPT-4o_annotated.json\n",
      "================================================================================\n",
      " Min Confidence Precision Recall F1-Score\n",
      "            0.7     0.457  0.759    0.570\n",
      "            0.8     0.455  0.723    0.558\n",
      "            0.9     0.441  0.590    0.505\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Confidence thresholds to test\n",
    "conf_thresholds = [0.7, 0.8, 0.9]\n",
    "\n",
    "all_tables = []  # store dataframes for optional later combination\n",
    "\n",
    "for evaluator in evaluators:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ðŸ“Œ Evaluator: {os.path.basename(evaluator.auto_path)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for conf in conf_thresholds:\n",
    "        res = evaluator.evaluate_precision_recall(min_confidence=conf)\n",
    "        g = res[\"global\"]\n",
    "\n",
    "        rows.append({\n",
    "            \"Min Confidence\": conf,\n",
    "            \"Precision\": g[\"precision\"],\n",
    "            \"Recall\": g[\"recall\"],\n",
    "            \"F1-Score\": g[\"f1-score\"],\n",
    "        })\n",
    "\n",
    "    df_better = pd.DataFrame(rows)\n",
    "    all_tables.append((evaluator, df_better))\n",
    "\n",
    "    # Pretty print table\n",
    "    print(df_better.to_string(index=False, formatters={\n",
    "        \"Precision\": \"{:.3f}\".format,\n",
    "        \"Recall\": \"{:.3f}\".format,\n",
    "        \"F1-Score\": \"{:.3f}\".format,\n",
    "    }))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc453a9c",
   "metadata": {},
   "source": [
    "## Calculate the distribution of different confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e66689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------\n",
    "# Collect confidence values from all outputs\n",
    "# -----------------------------------------\n",
    "\n",
    "confidence_values = []\n",
    "\n",
    "# Find all annotated files in outputs/\n",
    "for path in glob.glob(os.path.join(output_dir, \"*_annotated.json\")):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for ans in data[\"answers\"]:\n",
    "        annotations = ans.get(\"annotations\", {})\n",
    "        for theme, codes in annotations.items():\n",
    "            if theme == \"No Responses\":\n",
    "                continue\n",
    "\n",
    "            for code_name, instance in codes.items():\n",
    "\n",
    "                # Only count AI-generated annotations\n",
    "                annotator = instance.get(\"annotator\", \"\")\n",
    "                if annotator.lower() == \"human\":\n",
    "                    continue\n",
    "\n",
    "                conf = instance.get(\"confidence\", None)\n",
    "                if conf is not None:\n",
    "                    confidence_values.append(float(conf))\n",
    "\n",
    "# -----------------------------------------\n",
    "# Build DataFrame\n",
    "# -----------------------------------------\n",
    "\n",
    "conf_df = pd.DataFrame(confidence_values, columns=[\"confidence\"])\n",
    "\n",
    "# Optional: round to bins (e.g., 0.1 intervals)\n",
    "# conf_df[\"confidence_bin\"] = conf_df[\"confidence\"].round(1)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Plot distribution\n",
    "# -----------------------------------------\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "conf_df[\"confidence\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\"\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of AI Annotation Confidence Values\")\n",
    "plt.xlabel(\"Confidence Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4647f19",
   "metadata": {},
   "source": [
    "# Evaluate SimplePromptPipeline with Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6211ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GPT-3 (with Descriptions) ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries:   0%|                                      | 0/104 [00:00<?, ?entry/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:15<00:00,  1.38entry/s, Last: 1.00s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251109_141904.log\n",
      "\n",
      "=== Running GPT-4o-mini (with Descriptions) ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [02:19<00:00,  1.34s/entry, Last: 1.53s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251109_142019.log\n",
      "\n",
      "=== Running GPT-4o (with Descriptions) ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:54<00:00,  1.11s/entry, Last: 0.91s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251109_142238.log\n",
      "\n",
      "âœ… Evaluations with code descriptions completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Run pipelines + evaluate (with descriptions) ---\n",
    "records_desc = []\n",
    "\n",
    "for model_name, llm in models.items():\n",
    "    print(f\"\\n=== Running {model_name} (with Descriptions) ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run descriptive pipeline\n",
    "        pipeline = SimplePromptDescPipeline(llm=llm, input_path=gt_path, output_dir=output_dir)\n",
    "        maybe_path = pipeline.run()\n",
    "\n",
    "        # Create model-specific filename\n",
    "        model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        base_name = os.path.splitext(os.path.basename(gt_path))[0]\n",
    "        model_output_name = f\"{base_name}_{model_suffix}_desc_annotated.json\"\n",
    "        output_path = os.path.join(output_dir, model_output_name)\n",
    "\n",
    "        # If pipeline didnâ€™t save under that exact name, rename the generic one\n",
    "        if not os.path.exists(output_path):\n",
    "            generic_output = os.path.join(output_dir, f\"{base_name}_annotated.json\")\n",
    "            if os.path.exists(generic_output):\n",
    "                os.rename(generic_output, output_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Expected output file not found: {output_path}\")\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        records_desc.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "            \"Mode\": \"Desc\"  # mark these runs\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_desc = pd.DataFrame(records_desc)\n",
    "summary_df_desc = (\n",
    "    df_desc.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "           .mean()\n",
    "           .reset_index()\n",
    "           .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_desc.to_csv(os.path.join(results_dir, \"per_question_results_desc.csv\"), index=False)\n",
    "summary_df_desc.to_csv(os.path.join(results_dir, \"summary_results_desc.csv\"), index=False)\n",
    "\n",
    "print(\"\\nâœ… Evaluations with code descriptions completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b6f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ“Š Per-Question Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7d7c2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7d7c2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_7d7c2_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_7d7c2_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_7d7c2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_7d7c2_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "      <th id=\"T_7d7c2_level0_col5\" class=\"col_heading level0 col5\" >Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d7c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7d7c2_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_7d7c2_row0_col1\" class=\"data row0 col1\" >Q17</td>\n",
       "      <td id=\"T_7d7c2_row0_col2\" class=\"data row0 col2\" >0.400</td>\n",
       "      <td id=\"T_7d7c2_row0_col3\" class=\"data row0 col3\" >0.651</td>\n",
       "      <td id=\"T_7d7c2_row0_col4\" class=\"data row0 col4\" >0.495</td>\n",
       "      <td id=\"T_7d7c2_row0_col5\" class=\"data row0 col5\" >Desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d7c2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7d7c2_row1_col0\" class=\"data row1 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_7d7c2_row1_col1\" class=\"data row1 col1\" >Q17</td>\n",
       "      <td id=\"T_7d7c2_row1_col2\" class=\"data row1 col2\" >0.415</td>\n",
       "      <td id=\"T_7d7c2_row1_col3\" class=\"data row1 col3\" >0.819</td>\n",
       "      <td id=\"T_7d7c2_row1_col4\" class=\"data row1 col4\" >0.551</td>\n",
       "      <td id=\"T_7d7c2_row1_col5\" class=\"data row1 col5\" >Desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7d7c2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7d7c2_row2_col0\" class=\"data row2 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_7d7c2_row2_col1\" class=\"data row2 col1\" >Q17</td>\n",
       "      <td id=\"T_7d7c2_row2_col2\" class=\"data row2 col2\" >0.441</td>\n",
       "      <td id=\"T_7d7c2_row2_col3\" class=\"data row2 col3\" >0.759</td>\n",
       "      <td id=\"T_7d7c2_row2_col4\" class=\"data row2 col4\" >0.558</td>\n",
       "      <td id=\"T_7d7c2_row2_col5\" class=\"data row2 col5\" >Desc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1499cbb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ§® Average Precision/Recall per Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_92dd2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92dd2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_92dd2_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_92dd2_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_92dd2_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92dd2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_92dd2_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_92dd2_row0_col1\" class=\"data row0 col1\" >0.400</td>\n",
       "      <td id=\"T_92dd2_row0_col2\" class=\"data row0 col2\" >0.651</td>\n",
       "      <td id=\"T_92dd2_row0_col3\" class=\"data row0 col3\" >0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92dd2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_92dd2_row1_col0\" class=\"data row1 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_92dd2_row1_col1\" class=\"data row1 col1\" >0.441</td>\n",
       "      <td id=\"T_92dd2_row1_col2\" class=\"data row1 col2\" >0.759</td>\n",
       "      <td id=\"T_92dd2_row1_col3\" class=\"data row1 col3\" >0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92dd2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_92dd2_row2_col0\" class=\"data row2 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_92dd2_row2_col1\" class=\"data row2 col1\" >0.415</td>\n",
       "      <td id=\"T_92dd2_row2_col2\" class=\"data row2 col2\" >0.819</td>\n",
       "      <td id=\"T_92dd2_row2_col3\" class=\"data row2 col3\" >0.551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1499d4a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display Results (with graceful fallback if jinja2 missing) ---\n",
    "print(\"\\n\\n=== ðŸ“Š Per-Question Results ===\")\n",
    "try:\n",
    "    display(df_desc.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(df_desc.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "\n",
    "print(\"\\n\\n=== ðŸ§® Average Precision/Recall per Model ===\")\n",
    "try:\n",
    "    display(summary_df_desc.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(summary_df_desc.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94eb482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GPT-3 ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries:   0%|                                      | 0/105 [00:00<?, ?entry/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [01:21<00:00,  1.29entry/s, Last: 0.82s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q19_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q19_Annotated_Responses_20251109_153216.log\n",
      "\n",
      "=== Running GPT-4o ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [01:54<00:00,  1.09s/entry, Last: 0.82s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q19_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q19_Annotated_Responses_20251109_153337.log\n",
      "\n",
      "=== Running qwen3:4b ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [1:30:22<00:00, 51.64s/entry, Last: 65.34s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q19_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q19_Annotated_Responses_20251109_153531.log\n",
      "\n",
      "=== Running GPT-3 (with Descriptions) ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [01:23<00:00,  1.26entry/s, Last: 1.02s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q19_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q19_Annotated_Responses_20251109_170553.log\n",
      "\n",
      "=== Running GPT-4o (with Descriptions) ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [02:16<00:00,  1.30s/entry, Last: 1.23s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q19_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q19_Annotated_Responses_20251109_170716.log\n",
      "\n",
      "=== Running qwen3:4b (with Descriptions) ===\n",
      " â†’ Processing Q19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries:   0%|                                      | 0/105 [00:00<?, ?entry/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root (the directory that contains \"src\")\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- Imports from your project ---\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptPipeline\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptDescPipeline\n",
    "from src.app.Evaluator import Evaluator\n",
    "from src.llms.LLM_Wrappers import AbstractLLM\n",
    "\n",
    "# --- Define Models to Evaluate ---\n",
    "models = {\n",
    "    \"GPT-3\": AbstractLLM.from_name(\"gpt-3.5-turbo\"),\n",
    "    \"GPT-4o\": AbstractLLM.from_name(model_name=\"gpt-4o\"),\n",
    "    \"qwen3:4b\": AbstractLLM.from_name(model_name=\"qwen3:4b\"),\n",
    "}\n",
    "\n",
    "# --- Files to Evaluate ---\n",
    "ground_truth_files = [\n",
    "    # \"../src/data/Q17_Annotated_Responses.json\",\n",
    "    \"../src/data/Q19_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q20_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q21_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q22_Annotated_Responses.json\",\n",
    "]\n",
    "\n",
    "# --- Output and Results Directories ---\n",
    "output_dir = \"../outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_dir = os.path.join(\"../analysis\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Parameters ---\n",
    "min_conf = 0.7\n",
    "records = []\n",
    "\n",
    "# --- Run pipelines + evaluate ---\n",
    "for model_name, llm in models.items():\n",
    "    print(f\"\\n=== Running {model_name} ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run pipeline\n",
    "        pipeline = SimplePromptPipeline(llm=llm, input_path=gt_path, output_dir=output_dir)\n",
    "        maybe_path = pipeline.run()\n",
    "\n",
    "        # Create model-specific filename\n",
    "        model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        base_name = os.path.splitext(os.path.basename(gt_path))[0]\n",
    "        model_output_name = f\"{base_name}_{model_suffix}_annotated.json\"\n",
    "        output_path = os.path.join(output_dir, model_output_name)\n",
    "\n",
    "        # If pipeline didn't create that, rename existing _annotated.json file if present\n",
    "        if not os.path.exists(output_path):\n",
    "            generic_output = os.path.join(output_dir, f\"{base_name}_annotated.json\")\n",
    "            if os.path.exists(generic_output):\n",
    "                os.rename(generic_output, output_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Expected output file not found: {output_path}\")\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        records.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_better = pd.DataFrame(records)\n",
    "summary_df_better = (\n",
    "    df_better.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_better.to_csv(os.path.join(results_dir, \"per_question_results.csv\"), index=False)\n",
    "summary_df_better.to_csv(os.path.join(results_dir, \"summary_results.csv\"), index=False)\n",
    "\n",
    "# --- \n",
    "\n",
    "# --- Run pipelines + evaluate (with descriptions) ---\n",
    "records_desc = []\n",
    "\n",
    "for model_name, llm in models.items():\n",
    "    print(f\"\\n=== Running {model_name} (with Descriptions) ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run descriptive pipeline\n",
    "        pipeline = SimplePromptDescPipeline(llm=llm, input_path=gt_path, output_dir=output_dir)\n",
    "        maybe_path = pipeline.run()\n",
    "\n",
    "        # Create model-specific filename\n",
    "        model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        base_name = os.path.splitext(os.path.basename(gt_path))[0]\n",
    "        model_output_name = f\"{base_name}_{model_suffix}_desc_annotated.json\"\n",
    "        output_path = os.path.join(output_dir, model_output_name)\n",
    "\n",
    "        # If pipeline didnâ€™t save under that exact name, rename the generic one\n",
    "        if not os.path.exists(output_path):\n",
    "            generic_output = os.path.join(output_dir, f\"{base_name}_annotated.json\")\n",
    "            if os.path.exists(generic_output):\n",
    "                os.rename(generic_output, output_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Expected output file not found: {output_path}\")\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        records_desc.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "            \"Mode\": \"Desc\"  # mark these runs\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_desc = pd.DataFrame(records_desc)\n",
    "summary_df_desc = (\n",
    "    df_desc.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "           .mean()\n",
    "           .reset_index()\n",
    "           .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_desc.to_csv(os.path.join(results_dir, \"per_question_results_desc.csv\"), index=False)\n",
    "summary_df_desc.to_csv(os.path.join(results_dir, \"summary_results_desc.csv\"), index=False)\n",
    "\n",
    "print(\"\\nâœ… Evaluations with code descriptions completed successfully!\")\n",
    "\n",
    "# --- Display Results (with graceful fallback if jinja2 missing) ---\n",
    "print(\"\\n\\n=== ðŸ“Š Per-Question Results ===\")\n",
    "try:\n",
    "    display(df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "    display(df_desc.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "    print(df_desc.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "\n",
    "print(\"\\n\\n=== ðŸ§® Average Precision/Recall per Model ===\")\n",
    "try:\n",
    "    display(summary_df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "    display(summary_df_desc.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(summary_df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "    print(summary_df_desc.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e809c",
   "metadata": {},
   "source": [
    "# Evaluating SimplePrompt Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6dd8a",
   "metadata": {},
   "source": [
    "## Testing if adding Question helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05281610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GPT-4o-mini ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [02:09<00:00,  1.24s/entry, Last: 2.55s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251124_090100.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root (the directory that contains \"src\")\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- Imports from your project ---\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptPipeline\n",
    "from src.pipelines.SimplePromptPipeline import SimplePromptDescPipeline\n",
    "from src.app.Evaluator import Evaluator\n",
    "from src.llms.LLM_Wrappers import AbstractLLM\n",
    "\n",
    "# --- Define Models to Evaluate ---\n",
    "models = {\n",
    "    # \"GPT-3\": AbstractLLM.from_name(\"gpt-3.5-turbo\"),\n",
    "    \"GPT-4o-mini\": AbstractLLM.from_name(model_name=\"gpt-4o-mini\"),\n",
    "    # \"GPT-4o\": AbstractLLM.from_name(model_name=\"gpt-4o\"),\n",
    "}\n",
    "\n",
    "# --- Files to Evaluate ---\n",
    "ground_truth_files = [\n",
    "    \"../src/data/Q17_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q19_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q20_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q21_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q22_Annotated_Responses.json\",\n",
    "]\n",
    "\n",
    "# --- Output and Results Directories ---\n",
    "output_dir = \"../outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_dir = os.path.join(\"../analysis\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Parameters ---\n",
    "min_conf = 0.7\n",
    "records = []\n",
    "\n",
    "evaluators = []\n",
    "\n",
    "# --- Run pipelines + evaluate ---\n",
    "for model_name, llm in models.items():\n",
    "    print(f\"\\n=== Running {model_name} ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run pipeline\n",
    "        pipeline = SimplePromptPipeline(llm=llm, input_path=gt_path, output_dir=output_dir, use_cache=False)\n",
    "        maybe_path = pipeline.run()\n",
    "\n",
    "        # Create model-specific filename\n",
    "        model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        base_name = os.path.splitext(os.path.basename(gt_path))[0]\n",
    "        model_output_name = f\"{base_name}_{model_suffix}_annotated.json\"\n",
    "        output_path = os.path.join(output_dir, model_output_name)\n",
    "\n",
    "        # If pipeline didn't create that, rename existing _annotated.json file if present\n",
    "        if not os.path.exists(output_path):\n",
    "            generic_output = os.path.join(output_dir, f\"{base_name}_annotated.json\")\n",
    "            if os.path.exists(generic_output):\n",
    "                os.rename(generic_output, output_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Expected output file not found: {output_path}\")\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        evaluators.append(evaluator)\n",
    "\n",
    "        records.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_better = pd.DataFrame(records)\n",
    "summary_df_better = (\n",
    "    df_better.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_better.to_csv(os.path.join(results_dir, \"per_question_results.csv\"), index=False)\n",
    "summary_df_better.to_csv(os.path.join(results_dir, \"summary_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1602157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Precision    Recall  F1-Score\n",
      "0  GPT-4o-mini   0.403846  0.759036  0.527197\n"
     ]
    }
   ],
   "source": [
    "print(summary_df_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1744e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ“Š Per-Question Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_20581\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_20581_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_20581_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_20581_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_20581_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_20581_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_20581_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_20581_row0_col0\" class=\"data row0 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_20581_row0_col1\" class=\"data row0 col1\" >Q17</td>\n",
       "      <td id=\"T_20581_row0_col2\" class=\"data row0 col2\" >0.404</td>\n",
       "      <td id=\"T_20581_row0_col3\" class=\"data row0 col3\" >0.759</td>\n",
       "      <td id=\"T_20581_row0_col4\" class=\"data row0 col4\" >0.527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1376ca490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ§® Average Precision/Recall per Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7a46c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7a46c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_7a46c_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_7a46c_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_7a46c_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a46c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7a46c_row0_col0\" class=\"data row0 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_7a46c_row0_col1\" class=\"data row0 col1\" >0.404</td>\n",
       "      <td id=\"T_7a46c_row0_col2\" class=\"data row0 col2\" >0.759</td>\n",
       "      <td id=\"T_7a46c_row0_col3\" class=\"data row0 col3\" >0.527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17f376cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display Results (with graceful fallback if jinja2 missing) ---\n",
    "print(\"\\n\\n=== ðŸ“Š Per-Question Results ===\")\n",
    "try:\n",
    "    display(df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "\n",
    "print(\"\\n\\n=== ðŸ§® Average Precision/Recall per Model ===\")\n",
    "try:\n",
    "    display(summary_df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(summary_df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8d72c",
   "metadata": {},
   "source": [
    "## Test BetterPromptPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be2b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running GPT-3 ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:04<00:00,  1.62entry/s, Last: 1.02s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-3_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251124_093644.log\n",
      "\n",
      "=== Running GPT-4o-mini ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [04:06<00:00,  2.37s/entry, Last: 2.05s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-4o-mini_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251124_093748.log\n",
      "\n",
      "=== Running GPT-4o ===\n",
      " â†’ Processing Q17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [02:33<00:00,  1.48s/entry, Last: 2.55s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated JSON written to ../outputs/Q17_Annotated_Responses_GPT-4o_annotated.json\n",
      "Logs saved to logs/Q17_Annotated_Responses_20251124_094154.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root (the directory that contains \"src\")\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# --- Imports from your project ---\n",
    "from src.pipelines.BetterPromptPipeline import BetterPromptDescPipeline\n",
    "from src.app.Evaluator import Evaluator\n",
    "from src.llms.LLM_Wrappers import AbstractLLM\n",
    "\n",
    "# --- Define Models to Evaluate ---\n",
    "models = {\n",
    "    \"GPT-3\": AbstractLLM.from_name(\"gpt-3.5-turbo\"),\n",
    "    \"GPT-4o-mini\": AbstractLLM.from_name(model_name=\"gpt-4o-mini\"),\n",
    "    \"GPT-4o\": AbstractLLM.from_name(model_name=\"gpt-4o\"),\n",
    "}\n",
    "\n",
    "# --- Files to Evaluate ---\n",
    "ground_truth_files = [\n",
    "    \"../src/data/Q17_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q19_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q20_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q21_Annotated_Responses.json\",\n",
    "    # \"../src/data/Q22_Annotated_Responses.json\",\n",
    "]\n",
    "\n",
    "# --- Output and Results Directories ---\n",
    "output_dir = \"../outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_dir = os.path.join(\"../analysis\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# --- Parameters ---\n",
    "min_conf = 0.7\n",
    "records = []\n",
    "\n",
    "evaluators = []\n",
    "\n",
    "# --- Run pipelines + evaluate ---\n",
    "for model_name, llm in models.items():\n",
    "    model_suffix = model_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    print(f\"\\n=== Running {model_name} ===\")\n",
    "    for gt_path in ground_truth_files:\n",
    "        qname = os.path.basename(gt_path).replace(\"_Annotated_Responses.json\", \"\")\n",
    "        print(f\" â†’ Processing {qname}...\")\n",
    "\n",
    "        # Run pipeline\n",
    "\n",
    "        pipeline = BetterPromptDescPipeline(\n",
    "            llm=llm,\n",
    "            input_path=gt_path,\n",
    "            output_dir=output_dir,\n",
    "            output_name=model_suffix,\n",
    "        )\n",
    "        output_path = pipeline.run()\n",
    "\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluator = Evaluator(output_path, gt_path)\n",
    "        results = evaluator.evaluate_precision_recall(min_confidence=min_conf)\n",
    "        global_metrics = results[\"global\"]\n",
    "\n",
    "        evaluators.append(evaluator)\n",
    "\n",
    "        records.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Question\": qname,\n",
    "            \"Precision\": global_metrics[\"precision\"],\n",
    "            \"Recall\": global_metrics[\"recall\"],\n",
    "            \"F1-Score\": global_metrics[\"f1-score\"],\n",
    "        })\n",
    "\n",
    "# --- Build DataFrames ---\n",
    "df_better = pd.DataFrame(records)\n",
    "summary_df_better = (\n",
    "    df_better.groupby(\"Model\")[[\"Precision\", \"Recall\", \"F1-Score\"]]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"Model\")\n",
    ")\n",
    "\n",
    "# --- Save Results ---\n",
    "df_better.to_csv(os.path.join(results_dir, \"per_question_results.csv\"), index=False)\n",
    "summary_df_better.to_csv(os.path.join(results_dir, \"summary_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e736e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ“Š Per-Question Results ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_08149\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_08149_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_08149_level0_col1\" class=\"col_heading level0 col1\" >Question</th>\n",
       "      <th id=\"T_08149_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_08149_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_08149_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_08149_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_08149_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_08149_row0_col1\" class=\"data row0 col1\" >Q17</td>\n",
       "      <td id=\"T_08149_row0_col2\" class=\"data row0 col2\" >0.410</td>\n",
       "      <td id=\"T_08149_row0_col3\" class=\"data row0 col3\" >0.578</td>\n",
       "      <td id=\"T_08149_row0_col4\" class=\"data row0 col4\" >0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08149_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_08149_row1_col0\" class=\"data row1 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_08149_row1_col1\" class=\"data row1 col1\" >Q17</td>\n",
       "      <td id=\"T_08149_row1_col2\" class=\"data row1 col2\" >0.394</td>\n",
       "      <td id=\"T_08149_row1_col3\" class=\"data row1 col3\" >0.735</td>\n",
       "      <td id=\"T_08149_row1_col4\" class=\"data row1 col4\" >0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08149_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_08149_row2_col0\" class=\"data row2 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_08149_row2_col1\" class=\"data row2 col1\" >Q17</td>\n",
       "      <td id=\"T_08149_row2_col2\" class=\"data row2 col2\" >0.408</td>\n",
       "      <td id=\"T_08149_row2_col3\" class=\"data row2 col3\" >0.590</td>\n",
       "      <td id=\"T_08149_row2_col4\" class=\"data row2 col4\" >0.483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13759c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ðŸ§® Average Precision/Recall per Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_58fa1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_58fa1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_58fa1_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_58fa1_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_58fa1_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_58fa1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_58fa1_row0_col0\" class=\"data row0 col0\" >GPT-3</td>\n",
       "      <td id=\"T_58fa1_row0_col1\" class=\"data row0 col1\" >0.410</td>\n",
       "      <td id=\"T_58fa1_row0_col2\" class=\"data row0 col2\" >0.578</td>\n",
       "      <td id=\"T_58fa1_row0_col3\" class=\"data row0 col3\" >0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58fa1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_58fa1_row1_col0\" class=\"data row1 col0\" >GPT-4o</td>\n",
       "      <td id=\"T_58fa1_row1_col1\" class=\"data row1 col1\" >0.408</td>\n",
       "      <td id=\"T_58fa1_row1_col2\" class=\"data row1 col2\" >0.590</td>\n",
       "      <td id=\"T_58fa1_row1_col3\" class=\"data row1 col3\" >0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58fa1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_58fa1_row2_col0\" class=\"data row2 col0\" >GPT-4o-mini</td>\n",
       "      <td id=\"T_58fa1_row2_col1\" class=\"data row2 col1\" >0.394</td>\n",
       "      <td id=\"T_58fa1_row2_col2\" class=\"data row2 col2\" >0.735</td>\n",
       "      <td id=\"T_58fa1_row2_col3\" class=\"data row2 col3\" >0.513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x137663e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display Results (with graceful fallback if jinja2 missing) ---\n",
    "print(\"\\n\\n=== ðŸ“Š Per-Question Results ===\")\n",
    "try:\n",
    "    display(df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))\n",
    "\n",
    "print(\"\\n\\n=== ðŸ§® Average Precision/Recall per Model ===\")\n",
    "try:\n",
    "    display(summary_df_better.style.format({\"Precision\": \"{:.3f}\", \"Recall\": \"{:.3f}\", \"F1-Score\": \"{:.3f}\"}))\n",
    "except AttributeError:\n",
    "    print(summary_df_better.to_string(index=False, formatters={\"Precision\": \"{:.3f}\".format, \"Recall\": \"{:.3f}\".format, \"F1-Score\": \"{:.3f}\".format}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe644062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thematicLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
